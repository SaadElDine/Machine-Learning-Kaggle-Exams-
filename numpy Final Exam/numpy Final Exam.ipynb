{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> X =\n",
      " [[ 614  158 1958 ... 3918 1845 3335]\n",
      " [3125 3500 4437 ... 4458 2264 2139]\n",
      " [2685 4390 2462 ... 3362  827 1106]\n",
      " ...\n",
      " [ 270 2599 3352 ... 1658 1845 3297]\n",
      " [3172 3753 4784 ... 2839  266 3548]\n",
      " [4786 1961 2273 ...  530 2344 3839]]\n",
      "\n",
      "--> X size =  (1000, 20)\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "\n",
    "import numpy as np\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(0,5001,size = (1000,20))\n",
    "# print the shape of X\n",
    "print(\"--> X =\\n\",X)\n",
    "print()\n",
    "print(\"--> X size = \",X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = X.mean(axis = 0)\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = X.std(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Average Of Columns = \n",
      " [2529.534 2502.067 2407.71  2462.735 2457.845 2513.301 2500.081 2499.189\n",
      " 2526.756 2529.45  2528.428 2520.346 2521.432 2490.985 2525.904 2535.439\n",
      " 2561.252 2522.209 2435.77  2511.083]\n",
      "\n",
      "--> Average Of Columns Size =  (20,)\n",
      "\n",
      "--> Standard Deviation Of Columns = \n",
      " [1419.21916871 1450.04430295 1447.50003589 1432.63361428 1399.78505813\n",
      " 1445.12478022 1455.0272968  1441.81360074 1475.00944691 1457.94690421\n",
      " 1430.89778489 1470.4970698  1449.66524666 1482.53677957 1464.8819764\n",
      " 1453.30979983 1427.80034406 1439.68382408 1441.27156397 1444.19034691]\n",
      "\n",
      "--> Standard Deviation Of Columns Size =  (20,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(\"--> Average Of Columns = \\n\",ave_cols)\n",
    "print()\n",
    "print(\"--> Average Of Columns Size = \",ave_cols.shape)\n",
    "print()\n",
    "# Print the shape of std_cols\n",
    "print(\"--> Standard Deviation Of Columns = \\n\",std_cols)\n",
    "print()\n",
    "print(\"--> Standard Deviation Of Columns Size = \",std_cols.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> X noramlized = \n",
      " [[-1.34970979 -1.61654854 -0.31068048 ...  0.96951218 -0.40989499\n",
      "   0.57050444]\n",
      " [ 0.41957297  0.68820863  1.40192743 ...  1.34459453 -0.11917948\n",
      "  -0.25764125]\n",
      " [ 0.10954333  1.30198298  0.03750604 ...  0.58331627 -1.11621574\n",
      "  -0.97292092]\n",
      " ...\n",
      " [-1.59209659  0.0668483   0.65235922 ... -0.60027694 -0.40989499\n",
      "   0.54419212]\n",
      " [ 0.45268977  0.86268606  1.64165108 ...  0.22004206 -1.50545536\n",
      "   0.71799192]\n",
      " [ 1.58993484 -0.37313825 -0.0930639  ... -1.3837823  -0.06367294\n",
      "   0.9194889 ]]\n"
     ]
    }
   ],
   "source": [
    "# Mean normalize X\n",
    "X_norm = ( X - ave_cols ) / std_cols\n",
    "print(\"--> X noramlized = \\n\",X_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Average of all elements of X_normalized =  3.0908609005564356e-17\n",
      "\n",
      "--> Average of MINIMUM elements of X_normalized =  -1.728702714344412\n",
      "\n",
      "--> Average of MAXIMUM elements of X_normalized =  1.722622934326203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print(\"--> Average of all elements of X_normalized = \",X_norm.mean())\n",
    "print()\n",
    "# Print the average of the maximum value in eaprint()\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(\"--> Average of MINIMUM elements of X_normalized = \",X_norm.min(axis = 0).mean())\n",
    "print()\n",
    "print(\"--> Average of MAXIMUM elements of X_normalized = \",X_norm.max(axis = 0).mean())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4, 1, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Row indices = \n",
      " [415 124 926  76  97 325   9 663 224 259 187 437 353 268 851 820 121  16\n",
      " 833 834 831 370 225 945 198 261 916   1  85 176 183  92 732 202 231 730\n",
      " 166 921 796 647  50 664 356  78  94 913 982  56 645 238 173 413  87  64\n",
      " 512 378 962 835 382 668 573 161 675  33 594  53 264 701 958 707 934 632\n",
      " 885  61 721 507 659 470 394 392 444 876 970 464 652 818 949 678 175 185\n",
      " 143 672 305 355 145 112 989 528 798 282 702 380 761 696  48 447 584 727\n",
      " 323 640 928 336 217 933 357 822 792 442  20 657 152 953 236 399 618 211\n",
      " 465 116 735 854 178 521 114  54 248 590 318 552 170 517 125 156 631 765\n",
      " 432 979 390 593 602 153 541 462 244 354  99 313 362 374 670 551 821 243\n",
      " 644 439 709 866 219 518 424 887 978 364 287 103 539 420 363  46 599 973\n",
      " 827 216 453 772 230 639 882 342 427 621 167 500 148 858 623  43 638 904\n",
      " 286 596 484 491 381 720 544 141 361 923 252 265 266 791  27 304 917 498\n",
      " 345 234 671 903 557 940 641 168 785 239 193 188 637 773 690  47 482 489\n",
      " 290 457 877 412 561 991 794 396 992 256  22 403 891 942 339 271 757 209\n",
      " 514 739 790 985 133  45 857 446 950 922   2 959 150 510 450 589 620  26\n",
      " 421 527 777 417 448 425 280 134 184 531 925 476 452 300 811 249 771 201\n",
      " 842 977 511 969 909  88 212 974 515 480 100 200 810  11  19 603 995 980\n",
      " 338 897   5 429 817 310 302  89  96 839 122  52 294 351 158 138 848 609\n",
      " 784 601 110 423 258 131 952 127 297  75 966 776 747 767 295  29   6 186\n",
      " 182 372 538 606 433 467 872 751 823 246  41 586 536 694  80 486  63 503\n",
      " 419 293 769  74 250 291 614 564 583 344 610 987 674 915 939 306 485 105\n",
      " 843 768 443 683 222 520 196 617 206 750 285 680 253 786  23 890  81 177\n",
      " 655 580 556 756 961 731   3 828 737 648 951 692 490 113 788 666  38  71\n",
      " 787 213 401 889 598 955 162 633 102 626 289 578 532 540 642 965 414  28\n",
      " 334 722 288 591 667 129 568 389 493  35 369 741 766 865 459 711 816 585\n",
      " 106 502 745 436 613  73 714 475  10 393 477 929 946 764 729 964 506 947\n",
      " 478 164 861 155 368 635 679 749 825 174 107 560 571 210 492 819 322 254\n",
      " 999 227 725 883 497 712 838 717 983 879  70 943 190 481 567 326 941 874\n",
      " 352 375 160 651 163 860 416 307 775  67 494 704 504  40 181 658 875 279\n",
      " 159 649 852  32 867 588  18 553 410 377 753 411 846 856 806 251 460 455\n",
      " 203 379 428  21 782 451  49 526 321 622 893 892 262 778 616 301 870 607\n",
      " 137 327 840 165 700 269 309 383 537 676 240   4  62 488 881 270 646 315\n",
      " 218 135 330 813 172 726 142 449 960 199 324 179 228  59 687 595 853 204\n",
      " 902 912 906 744 469 495 689 661 385 815 562 908 800 329 529 108 686 335\n",
      " 509 273 483 636 331 215 993 328 905 660 736 574 566 559 918 826 653 841\n",
      " 919 530 523 522 629 272 862 278 830 994 699 849 774 130 260 780 976 845\n",
      " 864 146 706 814 801 343 760 366 303   8 350 988 998 501 673 886 535 781\n",
      " 194 968 445 710 513 365 242 808 910 836 914 898 847 237 795 665  42 154\n",
      " 341 406 572 311 308 349 274 191 298 144 376 391 911 214  31 597 733  60\n",
      "  95 799 388 716 931  12 118 713 257  66 850 920 837 123 762 587 630 197\n",
      " 809 971 277 461 868 900 555 132 650 384 499 669 755 894 558 220 360 684\n",
      " 195 681 404 229 708 226 972 547  37 232 466 581  57 981 956 247 463 400\n",
      " 101 569 524  65 546 592 703 770 398 754 855 371  17  30 789 519 932 387\n",
      "  93 117 180 233 677 565 359  25  34 157 734 600 373 471  55 550 505 844\n",
      " 688 267  24 986 627 136 805 619  82 276 948 147 340 793 832 139 582 367\n",
      " 358 936 797 434 149 348 604 888  51 223  58 346 468  98 548 957 759 577\n",
      " 111 192 625 407 954 207  72 241 612 863 742 807 319 907 456 740 283 967\n",
      " 570  15 634 873 869 317 151 316 140 533 691 189 575  91 697 169 405 314\n",
      " 758 263  69 472 104 896 615 332 126 579 441 859 871 542 643 748 693 431\n",
      " 984 320 698 884 935 611 120 397 996 208 128 656 418 804 944 779 255 205\n",
      " 473   0 723 829 878 109 901 426 474  14 824 545 549 430  90 724 292 624\n",
      " 899 508 938 719 386 812  36 752 347 763 296 395  68 563 576 440 454  84\n",
      "  83 333  44 963 682 115 685 715 337 281 408 534 299 554 525 221 802 990\n",
      " 997 718 975 705  77 479 402 743 662 924 422 628 695 409 496 738 487 245\n",
      " 438   7 728 783 880 608 803 930  79 235 543 746  39 605  86 927 119  13\n",
      " 654 171 937 895 284 312 516 435 275 458]\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices = np.random.permutation(1000) # x_norm.shape[0] \n",
    "print(\"--> Row indices = \\n\",row_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "\n",
    "\n",
    "# Create a Training Set\n",
    "X_train = X_norm[row_indices[:600],:]\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = X_norm[row_indices[600:800],:]\n",
    "\n",
    "# Create a Test Set\n",
    "X_test = X_norm[row_indices[800:1000],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> X Train = \n",
      " [[-0.05322222  0.85785862  0.83336095 ... -1.25180888 -0.92055518\n",
      "   0.81562448]\n",
      " [-0.2336031   1.71024637 -0.41085318 ...  1.44947867 -0.1719107\n",
      "   1.58560608]\n",
      " [ 1.49481211 -1.45655343  1.54907768 ...  0.15405535  1.1317992\n",
      "   0.02556242]\n",
      " ...\n",
      " [ 0.36531778  1.07026592  1.09380999 ... -0.14531593  0.0639921\n",
      "  -0.76103749]\n",
      " [-0.47458068 -1.09518516  1.7584041  ...  0.29644773 -0.42724079\n",
      "   1.3723378 ]\n",
      " [ 0.07008502 -0.66692238  0.38431087 ...  0.72293026 -0.76999368\n",
      "  -0.23825322]]\n",
      "\n",
      "--> X Train Size =  (600, 20)\n",
      "\n",
      "--> X Validation = \n",
      " [[-1.40466958 -0.58002848 -0.3797651  ... -1.03440004 -1.24665611\n",
      "   1.18538183]\n",
      " [ 0.78103934 -1.54758513  0.89346457 ... -1.2941793   1.18036742\n",
      "  -0.43836535]\n",
      " [-0.16455105  0.94475251 -0.14556822 ... -1.48936104  1.65078536\n",
      "   0.32607682]\n",
      " ...\n",
      " [-1.36098359 -1.11035711 -0.98356474 ... -0.14601053 -0.04216416\n",
      "  -0.21332576]\n",
      " [ 1.54061194 -1.03173882  1.31902587 ...  0.38396695 -1.02671144\n",
      "  -0.01598335]\n",
      " [ 0.64998136  0.88337508  1.77222103 ... -0.71141245 -0.5694763\n",
      "   1.29409326]]\n",
      "\n",
      "--> X Validation Size =  (200, 20)\n",
      "\n",
      "--> X Test = \n",
      " [[ 1.33838807  0.67855375 -1.629506   ...  1.54255467  1.57099471\n",
      "  -0.70910528]\n",
      " [-0.73246897  1.72265978 -1.31655264 ... -1.41364997  0.43935509\n",
      "   0.00409711]\n",
      " [-0.53517738  0.41787206 -1.08028322 ...  1.60576299  1.40863807\n",
      "   1.04551107]\n",
      " ...\n",
      " [-1.75345292 -0.56485653 -0.22087046 ... -0.69126914  1.04784555\n",
      "   1.21030929]\n",
      " [ 1.63925774  0.73924155 -0.65264938 ...  1.47934634  1.15677714\n",
      "  -1.03454714]\n",
      " [-0.20260014 -0.86484737 -0.91171673 ... -0.6322284   0.4351921\n",
      "   1.44365804]]\n",
      "\n",
      "--> X Test Size =  (200, 20)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print(\"--> X Train = \\n\",X_train)\n",
    "print()\n",
    "print(\"--> X Train Size = \",X_train.shape)\n",
    "print()\n",
    "# Print the shape of X_crossVal\n",
    "print(\"--> X Validation = \\n\",X_crossVal)\n",
    "print()\n",
    "print(\"--> X Validation Size = \",X_crossVal.shape)\n",
    "print()\n",
    "\n",
    "# Print the shape of X_test\n",
    "print(\"--> X Test = \\n\",X_test)\n",
    "print() \n",
    "print(\"--> X Test Size = \",X_test.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
